<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Body Part Tracker</title>
    <link
      rel="stylesheet"
      href="{{ url_for('static', filename='style.css') }}"
    />
  </head>
  <body>
    <div class="user-header">
      <span id="welcomeMessage"></span>
      <a href="/logout" class="logout-btn">Logout</a>
    </div>

    <h1>Body Part Tracker</h1>

    <div class="video-container">
      <video id="webcam" autoplay playsinline muted></video>
      <canvas id="output_canvas" class="output_canvas"></canvas>
    </div>

    <div class="controls">
      <label for="exerciseDescription">Describe your exercise:</label>
      <textarea
        id="exerciseDescription"
        rows="2"
        placeholder="e.g., 'I am doing bicep curls' or 'I am doing squats'"
      ></textarea>
      <button id="startStopBtn" type="button">Start Tracking</button>
      <p id="status">Status: Idle</p>
      <div id="analysisResult" class="analysis-result"></div>
    </div>

    <div class="advanced-controls controls">
      <button id="togglePromptsBtn" type="button">
        Show Advanced Settings
      </button>
      <div id="promptContainer" style="display: none; margin-top: 15px">
        <label for="formPrompt">Analysis Prompt:</label>
        <textarea id="formPrompt" rows="12"></textarea>
      </div>
    </div>

    <script type="module">
      // Fetch current user info
      fetch("/api/user")
        .then((r) => r.json())
        .then((data) => {
          if (data.username) {
            document.getElementById(
              "welcomeMessage"
            ).textContent = `Welcome, ${data.username}`;
          }
        })
        .catch(() => (window.location.href = "/login"));

      // 3. Import necessary components directly from the MediaPipe CDN
      import {
        PoseLandmarker,
        FilesetResolver,
        DrawingUtils,
      } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.12";

      const startStopBtn = document.getElementById("startStopBtn");
      const statusEl = document.getElementById("status");
      const analysisResultEl = document.getElementById("analysisResult");
      const togglePromptsBtn = document.getElementById("togglePromptsBtn");
      const promptContainer = document.getElementById("promptContainer");
      const formPromptEl = document.getElementById("formPrompt");
      const video = document.getElementById("webcam");
      const canvasElement = document.getElementById("output_canvas");
      const canvasCtx = canvasElement.getContext("2d");

      // The DrawingUtils constructor now takes the canvas context directly.
      const drawingUtils = new DrawingUtils(canvasCtx);

      // --- Constants for Landmark Processing ---
      const LANDMARK_NAMES = [
        "nose",
        "left_eye_inner",
        "left_eye",
        "left_eye_outer",
        "right_eye_inner",
        "right_eye",
        "right_eye_outer",
        "left_ear",
        "right_ear",
        "mouth_left",
        "mouth_right",
        "left_shoulder",
        "right_shoulder",
        "left_elbow",
        "right_elbow",
        "left_wrist",
        "right_wrist",
        "left_pinky",
        "right_pinky",
        "left_index",
        "right_index",
        "left_thumb",
        "right_thumb",
        "left_hip",
        "right_hip",
        "left_knee",
        "right_knee",
        "left_ankle",
        "right_ankle",
        "left_heel",
        "right_heel",
        "left_foot_index",
        "right_foot_index",
      ];

      // Select only the most important landmarks for exercise analysis
      const IMPORTANT_LANDMARKS = [
        "nose",
        "left_shoulder",
        "right_shoulder",
        "left_elbow",
        "right_elbow",
        "left_wrist",
        "right_wrist",
        "left_hip",
        "right_hip",
        "left_knee",
        "right_knee",
        "left_ankle",
        "right_ankle",
      ];

      let isTracking = false;
      let poseLandmarker;
      let lastVideoTime = -1;
      let collectedPoseData = []; // Array to store landmark data during tracking

      // Variables for visual smoothing (anti-flicker)
      let lastLandmarks = null;
      let lastLandmarkTime = 0;
      const MAX_DROPPED_FRAMES_MS = 500; // increased persistence
      let smoothedLandmarks = null;
      const SMOOTHING_ALPHA = 0.35; // lower = more smoothing

      const defaultFormPrompt = `
      You are an expert AI fitness coach. Your task is to analyze my performance for this exercise: '{user_description}'.

      Important Notes:

      The full body may not be visible in the data.

      Estimate speed and form based on whatever landmarks are available.

      The data I send will look like this simplified example:

      [
        {
          "timestamp": "2025-11-23T11:58:28.159Z",
          "landmarks": {
            "nose": { "x": 0.39, "y": 0.65, "z": -1.21, "visibility": 0.99 },
            "left_shoulder": { "x": 0.67, "y": 0.84, "z": -0.62, "visibility": 0.99 },
            "right_shoulder": { "x": 0.27, "y": 0.91, "z": -0.51, "visibility": 0.99 },
            "left_elbow": { "x": 0.93, "y": 0.90, "z": -1.11, "visibility": 0.92 },
            "left_wrist": { "x": 0.70, "y": 0.52, "z": -1.85, "visibility": 0.93 }
          }
        },
        ...
      ]


      Your Output Format:
      Return only a single JSON object:

      {
        "form_correctness": "<string>",
        "speed_pacing": "<string>",
        "corrective_feedback": "<string>",
        "overall_summary": "<string>"
      }

      **JSON Landmark Data:**
      \`\`\`json
      {truncated_json_data}
      \`\`\`
      `.trim();

      formPromptEl.value = defaultFormPrompt;

      // 4. Create and initialize the PoseLandmarker
      async function createPoseLandmarker() {
        setStatus("Loading AI Model...");
        const vision = await FilesetResolver.forVisionTasks(
          // Updated WASM path
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.12/wasm"
        );
        poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: `/models/pose_landmarker_lite.task`,
            delegate: "GPU",
          },
          runningMode: "VIDEO",
          numPoses: 1,
          minPoseDetectionConfidence: 0.55,
          minPosePresenceConfidence: 0.55,
          minTrackingConfidence: 0.55,
        });
        setStatus("Model loaded. Ready to start camera.");
        enableCam(); // Automatically start the camera after model loads
      }

      // 5. Enable the camera and start the prediction loop
      function enableCam() {
        if (!poseLandmarker) {
          console.log("Wait! poseLandmarker not loaded yet.");
          return;
        }

        navigator.mediaDevices
          .getUserMedia({ video: { width: 640, height: 480 } })
          .then((stream) => {
            video.srcObject = stream;
            video.addEventListener("loadeddata", predictWebcam);
            setStatus("Camera started. Click 'Start Tracking' to begin.");
          })
          .catch((err) => {
            console.error(err);
            setStatus(`Camera access error: ${err.message}`, true);
          });
      }

      // 6. The main prediction loop
      async function predictWebcam() {
        canvasElement.width = video.videoWidth;
        canvasElement.height = video.videoHeight;

        let startTimeMs = performance.now();
        if (lastVideoTime !== video.currentTime) {
          lastVideoTime = video.currentTime;
          poseLandmarker.detectForVideo(video, startTimeMs, (result) => {
            canvasCtx.save();
            // Soft fade instead of hard clear to reduce visual popping
            canvasCtx.fillStyle = "rgba(0,0,0,0.25)";
            canvasCtx.fillRect(0, 0, canvasElement.width, canvasElement.height);

            let rawLandmarks = null;

            if (result.landmarks && result.landmarks.length > 0) {
              rawLandmarks = result.landmarks[0];
              lastLandmarks = rawLandmarks;
              lastLandmarkTime = performance.now();
            } else if (
              lastLandmarks &&
              performance.now() - lastLandmarkTime < MAX_DROPPED_FRAMES_MS
            ) {
              rawLandmarks = lastLandmarks;
            }

            if (rawLandmarks) {
              // Initialize smoothedLandmarks first time
              if (!smoothedLandmarks) {
                smoothedLandmarks = rawLandmarks.map((l) => ({ ...l }));
              } else {
                // Exponential Moving Average smoothing
                for (let i = 0; i < rawLandmarks.length; i++) {
                  smoothedLandmarks[i].x =
                    smoothedLandmarks[i].x * (1 - SMOOTHING_ALPHA) +
                    rawLandmarks[i].x * SMOOTHING_ALPHA;
                  smoothedLandmarks[i].y =
                    smoothedLandmarks[i].y * (1 - SMOOTHING_ALPHA) +
                    rawLandmarks[i].y * SMOOTHING_ALPHA;
                  smoothedLandmarks[i].z =
                    smoothedLandmarks[i].z * (1 - SMOOTHING_ALPHA) +
                    rawLandmarks[i].z * SMOOTHING_ALPHA;
                  smoothedLandmarks[i].visibility = rawLandmarks[i].visibility;
                }
              }

              // Draw smoothed landmarks
              drawingUtils.drawLandmarks(smoothedLandmarks, {
                radius: (data) =>
                  DrawingUtils.lerp(data.from.z, -0.15, 0.1, 5, 2),
              });
              drawingUtils.drawConnectors(
                smoothedLandmarks,
                PoseLandmarker.POSE_CONNECTIONS,
                { color: "#FFFFFF", lineWidth: 5 } // thicker for stability
              );

              // Data collection uses raw (non-smoothed) for authenticity
              if (
                isTracking &&
                result.landmarks &&
                result.landmarks.length > 0
              ) {
                const timestamp = new Date().toISOString();
                const frameLandmarks = { timestamp, landmarks: {} };
                const currentLandmarks = result.landmarks[0];

                IMPORTANT_LANDMARKS.forEach((name) => {
                  const index = LANDMARK_NAMES.indexOf(name);
                  if (index !== -1 && currentLandmarks[index]) {
                    const lm = currentLandmarks[index];
                    const visible = lm.visibility > 0.45;
                    frameLandmarks.landmarks[name] = {
                      x: visible ? lm.x : 0,
                      y: visible ? lm.y : 0,
                      z: visible ? lm.z : 0,
                      visibility: lm.visibility,
                    };
                  } else {
                    frameLandmarks.landmarks[name] = {
                      x: 0,
                      y: 0,
                      z: 0,
                      visibility: 0,
                    };
                  }
                });
                collectedPoseData.push(frameLandmarks);
              }
            }
            canvasCtx.restore();
          });
        }
        window.requestAnimationFrame(predictWebcam);
      }

      function setStatus(text, isError = false) {
        statusEl.innerHTML = "Status: " + text;
        statusEl.className = isError ? "error" : "info";
      }

      function updateButtonState() {
        startStopBtn.textContent = isTracking
          ? "Stop & Analyze"
          : "Start Tracking";
        startStopBtn.disabled = false;
      }

      function startTracking() {
        isTracking = true;
        collectedPoseData = []; // Clear any previous data
        analysisResultEl.innerHTML = "";
        setStatus("Tracking... Perform your exercise.");
        console.log("Tracking started. Collecting pose data."); // Debugging log
        updateButtonState();
      }

      async function stopAndAnalyze() {
        isTracking = false;
        setStatus("Stopped. Analyzing exercise...");
        analysisResultEl.innerHTML = `<div class="loader"></div>Analyzing...`;
        console.log(
          `Tracking stopped. Collected ${collectedPoseData.length} data points.`
        ); // Debugging log
        updateButtonState(); // Visually stop the button immediately

        if (collectedPoseData.length === 0) {
          setStatus("Analysis failed: No pose data was collected.", true);
          analysisResultEl.innerHTML = `<p class="error"><strong>Error:</strong> Could not perform analysis because no movement was detected. Please try again.</p>`;
          updateButtonState();
          return;
        }

        const exerciseDescription = document.getElementById(
          "exerciseDescription"
        ).value;
        const formPrompt = formPromptEl.value;

        const startTime = performance.now();
        try {
          console.log("Sending data to server for analysis...", {
            count: collectedPoseData.length,
            description: exerciseDescription,
          }); // Debugging log

          const analysisResponse = await fetch("/analyze_exercise", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              pose_data: collectedPoseData,
              description: exerciseDescription,
              form_prompt: formPrompt,
            }),
          });

          const analysisData = await analysisResponse.json();
          const duration = ((performance.now() - startTime) / 1000).toFixed(2);

          if (analysisResponse.ok) {
            let html = `<h4>Analysis Results <span style="font-size: 12px; color: #555; font-weight: normal;">(${duration}s)</span></h4>`;
            if (analysisData.error) {
              html += `<p class="error"><strong>Analysis Error:</strong> ${analysisData.error}</p>`;
              html += `<p><strong>Model's Raw Response:</strong></p>`;
              html += `<pre class="raw-response">${analysisData.raw_response}</pre>`;
            } else {
              html += `<p><strong>Form & Correctness:</strong> ${analysisData.form_correctness}</p>`;
              html += `<p><strong>Speed & Pacing:</strong> ${analysisData.speed_pacing}</p>`;
              html += `<p><strong>Corrective Feedback:</strong> ${analysisData.corrective_feedback}</p>`;
              html += `<p><strong>Overall Summary:</strong> ${analysisData.overall_summary}</p>`;
            }
            analysisResultEl.innerHTML = html;
            setStatus("Analysis complete.");
          } else {
            throw new Error(analysisData.error || "Analysis failed");
          }
        } catch (analysisError) {
          analysisResultEl.innerHTML = `<span class="error">Analysis failed: ${analysisError.message}</span>`;
          setStatus("Analysis failed.", true);
        } finally {
          collectedPoseData = []; // Clear data after analysis
          updateButtonState();
        }
      }

      startStopBtn.addEventListener("click", () => {
        startStopBtn.disabled = true;
        if (isTracking) {
          stopAndAnalyze();
        } else {
          startTracking();
        }
      });

      togglePromptsBtn.addEventListener("click", () => {
        const isHidden = promptContainer.style.display === "none";
        promptContainer.style.display = isHidden ? "block" : "none";
        togglePromptsBtn.textContent = isHidden
          ? "Hide Advanced Settings"
          : "Show Advanced Settings";
      });

      // --- Initial state ---
      createPoseLandmarker();
      updateButtonState();

      function renderAnalysis(data) {
        if (data.error) {
          analysisResultEl.innerHTML = `<div class="error">${data.error}</div>`;
          return;
        }
        const fc = data.form_correctness || "";
        const sp = data.speed_pacing || "";
        const cf = data.corrective_feedback || "";
        const osum = data.overall_summary || "";
        analysisResultEl.innerHTML = `
          <strong>Form & Correctness:</strong> ${fc}<br><br>
          <strong>Speed & Pacing:</strong> ${sp}<br><br>
          <strong>Corrective Feedback:</strong> ${cf}<br><br>
          <strong>Overall Summary:</strong> ${osum}
        `;
      }

      // Example placeholder call (replace with actual fetch when analysis completes)
      // fetch('/analyze_exercise', {method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify(payload)})
      //   .then(r=>r.json()).then(renderAnalysis).catch(e=>console.error(e));
    </script>
  </body>
</html>
